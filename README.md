# Awesome - Interpretable Machine Leanring Papers/Books

A list of the interpretable machine learning papers. The purpose of this list is to encourage transportation researchers interested in the world of interpretable machine learning.

## Background

You can also follow some *awesome paper lists*, for example, [Deep Learning](https://github.com/terryum/awesome-deep-learning-papers), [Deep Vision](https://github.com/kjw0612/awesome-deep-vision) and [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn), [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap).
 
**We need your contributions!**

If you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.


## Contents


### Concepts/Algorithms
- **Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning** (2018), B. Biggio, and F. Roli [[pdf]](https://arxiv.org/pdf/1712.03141.pdf)
- **Understanding Black-box Predictions via Influence Functions** (2018), P. Koh, and P. Liang [[pdf]](https://arxiv.org/pdf/1703.04730.pdf)
- **Model Class Reliance: Variable Importance Measures for any Machine Learning Model Class, from the "Rashomon" Perspective** (2018), A. Fisher et al. [[pdf]](https://arxiv.org/pdf/1801.01489.pdf)
- **Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models** (2018), D. Apley [[pdf]](https://christophm.github.io/interpretable-ml-book/feature-importance.html)
- **Understanding Black-box Predictions via Influence Functions** (2017), P. Koh, and P. Liang [[pdf]](https://arxiv.org/pdf/1703.04730.pdf)
- **Practical Black-Box Attacks against Machine Learning** (2017), N. Papernot et al. [[pdf]](https://arxiv.org/pdf/1602.02697.pdf)
- **Inverse Classification for Comparison-based Interpretability in Machine Learning** (2017), T. Laugel et al. [[pdf]](https://arxiv.org/pdf/1712.08443.pdf)
- **An unexpected unity among methods for interpreting model predictions** (2016), S. Lundberg, and S. Lee [[pdf]](https://arxiv.org/pdf/1712.08443.pdf)
- **Why should i trust you?: Explaining the predictions of any classifier.** (2016), M. Ribeiro et al. [[pdf]](http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf)
- **Examples are not enough, learn to criticize! criticism for interpretability** (2016), P. Koh, and P. Liang [[pdf]](https://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf)

### Text Data
- **"What is relevant in a text document?": An interpretable machine learning approach** (2017), L.Arras et al. [[pdf]](http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0181142&type=printable)
- **Explaining Data-Driven Document Classifications** (2014), G. Hinton et al. [[pdf]](http://pages.stern.nyu.edu/~fprovost/Papers/MartensProvost_Explaining.pdf)


### R Packages
- **lime** (2018), T. Pedersen [[github]](https://github.com/thomasp85/lime)
- **DALEX** (2018), P. Biecek  [[weblink]](https://pbiecek.github.io/DALEX_docs/)
- **lightgbmExplainer** (2018), P. Biecek  [[github]](https://github.com/lantanacamara/lightgbmExplainer)
- **randomForestExplainer** (2018), A. Paluszynska, and P. Biecek  [[github]](https://github.com/MI2DataLab/randomForestExplainer)


### Gitbook
- **A Guide for Making Black Box Models Explainable.** (2018), C. Molnar [[gitbook]](https://christophm.github.io/interpretable-ml-book/)



